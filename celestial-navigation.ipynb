{
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNeKi7KuIT6tQnU5xI5Y1E8",
   "machine_shape": "hm",
   "mount_file_id": "1qUHcsA7pbMz7BckO-v8dQgmLMclTPrJe",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "vscode": {
   "interpreter": {
    "hash": "cda0ac541ab6c535dcb4ffe1de6394d0d0ba460ea4bcec2c3250fd08f595b9ac"
   }
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 7029505,
     "sourceType": "datasetVersion",
     "datasetId": 4043165
    },
    {
     "sourceId": 7029168,
     "sourceType": "datasetVersion",
     "datasetId": 4042934
    },
    {
     "sourceId": 7029134,
     "sourceType": "datasetVersion",
     "datasetId": 4042911
    }
   ],
   "dockerImageVersionId": 30587,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import datetime as dt\n",
    "\n",
    "# opencv\n",
    "import cv2\n",
    "\n",
    "# tensorflow/keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Lambda, Concatenate,Flatten, concatenate, LSTM, MaxPooling2D, Permute, Reshape, TimeDistributed\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 3662,
     "status": "ok",
     "timestamp": 1675627250240,
     "user": {
      "displayName": "Alex Spradling",
      "userId": "03803427225004929883"
     },
     "user_tz": 300
    },
    "id": "bT-hwhnzn67Q",
    "execution": {
     "iopub.status.busy": "2023-11-23T03:54:40.863527Z",
     "iopub.execute_input": "2023-11-23T03:54:40.864024Z",
     "iopub.status.idle": "2023-11-23T03:54:41.625145Z",
     "shell.execute_reply.started": "2023-11-23T03:54:40.863987Z",
     "shell.execute_reply": "2023-11-23T03:54:41.623906Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Get lists of file names and labels",
   "metadata": {
    "id": "zXESshqdYYqm"
   }
  },
  {
   "cell_type": "code",
   "source": "print('Training images :', len(os.listdir('/kaggle/input/skyfield-train-kolkata-andaman/0'))) # should now have 90% of the files\n\n# training\nfiles_train = os.listdir('/kaggle/input/skyfield-train-kolkata-andaman/0')\nfiles_train = [f for f in files_train if f.endswith('.png')]\n\n# sort\nfiles = sorted(files_train)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675627435021,
     "user": {
      "displayName": "Alex Spradling",
      "userId": "03803427225004929883"
     },
     "user_tz": 300
    },
    "id": "eHS-sGUAiyRS",
    "outputId": "b9c781e3-e166-44f6-8519-2dd83f28ed52",
    "execution": {
     "iopub.status.busy": "2023-11-23T03:55:08.003966Z",
     "iopub.execute_input": "2023-11-23T03:55:08.004350Z",
     "iopub.status.idle": "2023-11-23T03:55:08.382043Z",
     "shell.execute_reply.started": "2023-11-23T03:55:08.004321Z",
     "shell.execute_reply": "2023-11-23T03:55:08.380845Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "Training images : 15506\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---",
   "metadata": {
    "id": "vTp_K0qojw5Q"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Function to Extract Position and Time from Image File Title",
   "metadata": {
    "id": "tP9dVNfdCNht"
   }
  },
  {
   "cell_type": "code",
   "source": "# extract position and time from filename\n\ndef extract_position_time(filepath):\n    \"\"\"\n    The labels corresponding to the image are encoded in the title. This function\n    parses the labels.\n\n    args\n    ---\n    filepath(str): ex: cloud_cover0/L38.0241LON-138.9065T2020-03-13-04-00-00.png\n    \n    The string is parsed to extract the latitude, longitude and time of the image.\n    \"\"\"\n    # filename = filepath.split(\"/\")[-1]\n    filename = filepath\n    # extract position\n    lat = re.search('L(.*?)LON', filename).group(1)\n    long = re.search('LON(.*?)T', filename).group(1)\n    # extract time\n    time = re.search('T(.*?)\\.png', filename).group(1)\n    # convert time to np.datetime64\n    time = dt.datetime.strptime(time, '%Y-%m-%d-%H-%M-%S')\n    time = np.datetime64(time)\n    # return position and time\n    return (float(lat), float(long)), time\n",
   "metadata": {
    "executionInfo": {
     "elapsed": 801,
     "status": "ok",
     "timestamp": 1675627400771,
     "user": {
      "displayName": "Alex Spradling",
      "userId": "03803427225004929883"
     },
     "user_tz": 300
    },
    "id": "wNzAUO9PnSin"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Functions to normalize training data",
   "metadata": {
    "id": "9S19rUrskcZX"
   }
  },
  {
   "cell_type": "code",
   "source": "\ndef normalize_times(times_array, master_times):\n \n    times = np.array(times_array)\n    times = (times - master_times.min()) / (master_times.max() - master_times.min())\n    return times\n\ndef normalize_datetime(time, min_time, max_time):\n    \n    # normalize the datetime64 object\n    normalized_time = (time - min_time) / (max_time - min_time)\n    return normalized_time\n\ndef normalize_y(pos_array, master_pos):\n    lat_min, lat_range, long_min, long_range = get_lat_long_bounds(master_pos)\n    \n    y_norm = np.zeros(pos_array.shape)\n    \n    y_norm[:,0] = (pos_array[:,0] - lat_min) / lat_range\n    y_norm[:,1] = (pos_array[:,1] - long_min) / long_range\n\n    return y_norm\n\ndef get_lat_long_bounds(y):\n    lat_min = y[:,0].min()\n    lat_max = y[:,0].max()\n    long_min = y[:,1].min()\n    long_max = y[:,1].max()\n    lat_range = lat_max - lat_min\n    long_range = long_max - long_min\n    return lat_min, lat_range, long_min, long_range\n  ",
   "metadata": {
    "executionInfo": {
     "elapsed": 675,
     "status": "ok",
     "timestamp": 1675627406901,
     "user": {
      "displayName": "Alex Spradling",
      "userId": "03803427225004929883"
     },
     "user_tz": 300
    },
    "id": "gEak2ceoAFvi"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Prepare Training Data",
   "metadata": {
    "id": "hxf2GLJTlY5h"
   }
  },
  {
   "cell_type": "code",
   "source": "# create array of position\nposition = np.array([extract_position_time(f)[0] for f in files])\n\n# create array of time\ntimes = np.array([extract_position_time(f)[1] for f in files])\n\n# normalize positions\ny_norm = normalize_y(position, position)\n\n# normalize times\nnorm_times = normalize_times(times, times)\n#############",
   "metadata": {
    "executionInfo": {
     "elapsed": 2741,
     "status": "ok",
     "timestamp": 1675627442072,
     "user": {
      "displayName": "Alex Spradling",
      "userId": "03803427225004929883"
     },
     "user_tz": 300
    },
    "id": "wB1B5LDolbMH"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Loss Functions",
   "metadata": {
    "id": "XcjPxWND0IbY"
   }
  },
  {
   "cell_type": "code",
   "source": "def haversine_loss(y_true, y_pred, R=3443.92):\n    # shamelessly borrowed from this very similar project: https://github.com/gregtozzi/deep_learning_celnav\n    \n    # Convert normalized lat and long into actuals\n    lat_min, lat_range, long_min, long_range = get_lat_long_bounds(position)\n    lat1  = y_true[:,0] * lat_range + lat_min\n    lat2  = y_pred[:,0] * lat_range + lat_min\n    long1 = y_true[:,1] * long_range + long_min\n    long2 = y_pred[:,1] * long_range + long_min \n    \n    # Compute phis and lambdas \n    phi1 = lat1 * np.pi / 180\n    phi2 = lat2 * np.pi / 180\n    delta_phi    = (lat2 - lat1) * np.pi / 180\n    delta_lambda = (long2 - long1) * np.pi / 180\n    \n    # Intermediate computations\n    a = tf.square(tf.sin(delta_phi / 2)) + tf.cos(phi1) * tf.cos(phi2) * tf.square(tf.sin(delta_lambda / 2))\n    c = 2 * tf.atan2(tf.sqrt(a), tf.sqrt(1 - a))\n    \n    # Compute distances\n    d = R * c\n    \n    # Compute the mean squared distance (MSE)\n    return tf.reduce_mean(d)",
   "metadata": {
    "executionInfo": {
     "elapsed": 824,
     "status": "ok",
     "timestamp": 1675627446413,
     "user": {
      "displayName": "Alex Spradling",
      "userId": "03803427225004929883"
     },
     "user_tz": 300
    },
    "id": "Vh5YqfTj5xgs"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Early Stopping",
   "metadata": {
    "id": "gDRWH2xsJlvE"
   }
  },
  {
   "cell_type": "code",
   "source": "\n# define the early stopping callback\nearly_stopping = EarlyStopping(monitor='loss', min_delta=0.01, patience=10)\n",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1675627450542,
     "user": {
      "displayName": "Alex Spradling",
      "userId": "03803427225004929883"
     },
     "user_tz": 300
    },
    "id": "22vHKLGyJno4"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# EXPERIMENTAL MODEL",
   "metadata": {
    "id": "IB8jgt6aqHzU"
   }
  },
  {
   "cell_type": "code",
   "source": "\n# define the input layers\nsamples_size = 41 \ninput_image = Input(shape=(samples_size, 224,224,1))\ninput_time = Input(shape=(samples_size, 1))\n\n# process the input image using a CNN\nx = TimeDistributed(Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'))(input_image)\nx = TimeDistributed(MaxPooling2D())(x)\nx = TimeDistributed(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))(x)\nx = TimeDistributed(MaxPooling2D())(x)\nx = TimeDistributed(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))(x)\nx = TimeDistributed(Flatten())(x)\n\n# flatten the input time\nt = TimeDistributed(Flatten())(input_time)\n\n# concatenate the CNN and LSTM outputs\nz = concatenate([x, t])\n\n# pass to LSTM\nz = LSTM(64, activation='relu', return_sequences=True)(z)\n\n# z = concatenate([x, t])\nz = Dense(64, activation='relu')(z)\nz = Dropout(0.2)(z)\noutputs = Dense(2, activation='sigmoid')(z)\nprint(outputs)\n\n# define the model\nexperimental_model = Model(inputs=[input_image, input_time], outputs=outputs)\nexperimental_model.summary()",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1675365193003,
     "user": {
      "displayName": "Alex Spradling",
      "userId": "03803427225004929883"
     },
     "user_tz": 300
    },
    "id": "P9FgzyZzn29N",
    "outputId": "97bdf275-a3c5-4bbb-9b4e-c1f3885a80f8"
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "KerasTensor(type_spec=TensorSpec(shape=(None, 41, 2), dtype=tf.float32, name=None), name='dense_10/Sigmoid:0', description=\"created by layer 'dense_10'\")\n\nModel: \"model_3\"\n\n__________________________________________________________________________________________________\n\n Layer (type)                   Output Shape         Param #     Connected to                     \n\n==================================================================================================\n\n input_7 (InputLayer)           [(None, 41, 224, 22  0           []                               \n\n                                4, 1)]                                                            \n\n                                                                                                  \n\n time_distributed (TimeDistribu  (None, 41, 224, 224  160        ['input_7[0][0]']                \n\n ted)                           , 16)                                                             \n\n                                                                                                  \n\n time_distributed_1 (TimeDistri  (None, 41, 112, 112  0          ['time_distributed[0][0]']       \n\n buted)                         , 16)                                                             \n\n                                                                                                  \n\n time_distributed_2 (TimeDistri  (None, 41, 112, 112  4640       ['time_distributed_1[0][0]']     \n\n buted)                         , 32)                                                             \n\n                                                                                                  \n\n time_distributed_3 (TimeDistri  (None, 41, 56, 56,   0          ['time_distributed_2[0][0]']     \n\n buted)                         32)                                                               \n\n                                                                                                  \n\n time_distributed_4 (TimeDistri  (None, 41, 56, 56,   18496      ['time_distributed_3[0][0]']     \n\n buted)                         64)                                                               \n\n                                                                                                  \n\n input_8 (InputLayer)           [(None, 41, 1)]      0           []                               \n\n                                                                                                  \n\n time_distributed_5 (TimeDistri  (None, 41, 200704)  0           ['time_distributed_4[0][0]']     \n\n buted)                                                                                           \n\n                                                                                                  \n\n time_distributed_6 (TimeDistri  (None, 41, 1)       0           ['input_8[0][0]']                \n\n buted)                                                                                           \n\n                                                                                                  \n\n concatenate_3 (Concatenate)    (None, 41, 200705)   0           ['time_distributed_5[0][0]',     \n\n                                                                  'time_distributed_6[0][0]']     \n\n                                                                                                  \n\n lstm_6 (LSTM)                  (None, 41, 64)       51397120    ['concatenate_3[0][0]']          \n\n                                                                                                  \n\n dense_9 (Dense)                (None, 41, 64)       4160        ['lstm_6[0][0]']                 \n\n                                                                                                  \n\n dropout (Dropout)              (None, 41, 64)       0           ['dense_9[0][0]']                \n\n                                                                                                  \n\n dense_10 (Dense)               (None, 41, 2)        130         ['dropout[0][0]']                \n\n                                                                                                  \n\n==================================================================================================\n\nTotal params: 51,424,706\n\nTrainable params: 51,424,706\n\nNon-trainable params: 0\n\n__________________________________________________________________________________________________\n"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# MonteCarlo Drop Out Layers\n\n- Based on this idea: https://towardsdatascience.com/monte-carlo-dropout-7fd52f8b6571#:~:text=Monte%20Carlo%20Dropout%20boils%20down,softmax%20outputs%20for%20each%20class.",
   "metadata": {
    "id": "2Dle_nteIsso"
   }
  },
  {
   "cell_type": "code",
   "source": "# from tensorflow.keras.layers import Layer\nclass MCdropout(Dropout):\n    def call(self, inputs):\n        return super().call(inputs, training=True)\n\ninput_image = Input(shape=(224,224,1))\ninput_time = Input(shape=times[0].shape)\n\nx = Conv2D(filters=16, kernel_size=3, padding='same', activation='relu')(input_image)\nx = MaxPooling2D()(x)\nx = Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')(x)\nx = MaxPooling2D()(x)\nx = Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')(x)\nx = Flatten()(x)\n\n# flatten the input time\nt = Flatten()(input_time)\n\n# Pass the time input through 3 dense layers\nt = Dense(128, activation='relu')(t)\nt = Dense(64, activation='relu')(t)\nt = Dense(32, activation='relu')(t)\n\n# concatenate the output of the CNN and Dense layers \nz = concatenate([x, t])\nz = Dense(256, activation='relu')(z)\nz = MCdropout(0.2)(z) # MC Dropout layer\nz = Dense(256, activation='relu')(z)\nz = MCdropout(0.2)(z) # MC Dropout layer\noutputs = Dense(2, activation='sigmoid')(z)\n\nmc_model = Model(inputs=[input_image, input_time], outputs=outputs)\nmc_model.summary()",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1157,
     "status": "ok",
     "timestamp": 1675627514778,
     "user": {
      "displayName": "Alex Spradling",
      "userId": "03803427225004929883"
     },
     "user_tz": 300
    },
    "id": "dexVcxeWDSS2",
    "outputId": "4754cf6a-047b-4157-c600-90f5338909ce"
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"model\"\n\n__________________________________________________________________________________________________\n\n Layer (type)                   Output Shape         Param #     Connected to                     \n\n==================================================================================================\n\n input_1 (InputLayer)           [(None, 224, 224, 1  0           []                               \n\n                                )]                                                                \n\n                                                                                                  \n\n conv2d (Conv2D)                (None, 224, 224, 16  160         ['input_1[0][0]']                \n\n                                )                                                                 \n\n                                                                                                  \n\n max_pooling2d (MaxPooling2D)   (None, 112, 112, 16  0           ['conv2d[0][0]']                 \n\n                                )                                                                 \n\n                                                                                                  \n\n input_2 (InputLayer)           [(None,)]            0           []                               \n\n                                                                                                  \n\n conv2d_1 (Conv2D)              (None, 112, 112, 32  4640        ['max_pooling2d[0][0]']          \n\n                                )                                                                 \n\n                                                                                                  \n\n flatten_1 (Flatten)            (None, 1)            0           ['input_2[0][0]']                \n\n                                                                                                  \n\n max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 32)  0           ['conv2d_1[0][0]']               \n\n                                                                                                  \n\n dense (Dense)                  (None, 128)          256         ['flatten_1[0][0]']              \n\n                                                                                                  \n\n conv2d_2 (Conv2D)              (None, 56, 56, 64)   18496       ['max_pooling2d_1[0][0]']        \n\n                                                                                                  \n\n dense_1 (Dense)                (None, 64)           8256        ['dense[0][0]']                  \n\n                                                                                                  \n\n flatten (Flatten)              (None, 200704)       0           ['conv2d_2[0][0]']               \n\n                                                                                                  \n\n dense_2 (Dense)                (None, 32)           2080        ['dense_1[0][0]']                \n\n                                                                                                  \n\n concatenate (Concatenate)      (None, 200736)       0           ['flatten[0][0]',                \n\n                                                                  'dense_2[0][0]']                \n\n                                                                                                  \n\n dense_3 (Dense)                (None, 256)          51388672    ['concatenate[0][0]']            \n\n                                                                                                  \n\n m_cdropout (MCdropout)         (None, 256)          0           ['dense_3[0][0]']                \n\n                                                                                                  \n\n dense_4 (Dense)                (None, 256)          65792       ['m_cdropout[0][0]']             \n\n                                                                                                  \n\n m_cdropout_1 (MCdropout)       (None, 256)          0           ['dense_4[0][0]']                \n\n                                                                                                  \n\n dense_5 (Dense)                (None, 2)            514         ['m_cdropout_1[0][0]']           \n\n                                                                                                  \n\n==================================================================================================\n\nTotal params: 51,488,866\n\nTrainable params: 51,488,866\n\nNon-trainable params: 0\n\n__________________________________________________________________________________________________\n"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Custom Transformer Code",
   "metadata": {
    "id": "2YkpHWP_IN6A"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Current Custom Generator",
   "metadata": {
    "id": "emMB6DG0lBgg"
   }
  },
  {
   "cell_type": "code",
   "source": "class CustomGenerator(Sequence):\n    def __init__(self, directory, batch_size=32, segment = 'Train'):\n        \n        self.directory = directory\n        self.batch_size = batch_size\n        self.segment = segment\n\n    def __len__(self):\n        if self.segment !='Train':\n            return int(np.floor(len(files_val) / self.batch_size))\n        else:\n            return int(np.floor(len(files_train) / self.batch_size))\n\n    def __getitem__(self, idx):\n\n        # get batch of images\n        batch = os.listdir(self.directory)[idx * self.batch_size:(idx + 1) * self.batch_size]\n        # create empty array to hold images\n        # batch.sort()\n        x = np.empty((self.batch_size, 224, 224, 1))\n        y = np.zeros((self.batch_size, 2))\n        times_gen = []\n        # loop through batch\n        for i, img in enumerate(batch):\n            # populate time and position labels \n            y[i] = extract_position_time(img)[0]\n            time = extract_position_time(img)[1]\n            times_gen.append(normalize_datetime(time, times.min(), times.max()))\n             # read image\n            img = cv2.imread(os.path.join(self.directory, img),0)\n            img = cv2.resize(img, (224, 224))\n            # add image to x\n            x[i] = img.reshape(224, 224, 1)\n        # get output\n        output = normalize_y(y, position)\n        # get time input\n        time_input = np.array(times_gen) \n        \n        return [x/255, time_input], output\n\ncustom_gen_train = CustomGenerator(directory = '/kaggle/input/skyfield-train-kolkata-andaman/0', segment = 'Train')\ncustom_gen_val = CustomGenerator(directory = '/kaggle/input/skyfield-kolkata-andaman-val/0_val', segment = 'Validate')",
   "metadata": {
    "executionInfo": {
     "elapsed": 765,
     "status": "ok",
     "timestamp": 1675627522161,
     "user": {
      "displayName": "Alex Spradling",
      "userId": "03803427225004929883"
     },
     "user_tz": 300
    },
    "id": "7E055lmHGmTX"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "with tf.device(device_name):\n  # Compile and train the model\n    mc_model.compile(optimizer='adam', loss=haversine_loss, metrics=haversine_loss)\n    history_mc = mc_model.fit(custom_gen_train, batch_size = 32, epochs = 100, shuffle = False, callbacks = [early_stopping])\n\nmc_model.save('../content/drive/MyDrive/mc_model.h5')",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28458185,
     "status": "ok",
     "timestamp": 1675655995913,
     "user": {
      "displayName": "Alex Spradling",
      "userId": "03803427225004929883"
     },
     "user_tz": 300
    },
    "id": "guS1xVTISq4Y",
    "outputId": "a305c3c2-6aa4-495c-ca29-fec93a6653ad"
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/100\n\n2458/2458 [==============================] - 425s 169ms/step - loss: 4.4668 - haversine_loss: 4.4668\n\nEpoch 2/100\n\n2458/2458 [==============================] - 414s 168ms/step - loss: 2.7526 - haversine_loss: 2.7526\n\nEpoch 3/100\n\n2458/2458 [==============================] - 415s 169ms/step - loss: 2.4993 - haversine_loss: 2.4993\n\nEpoch 4/100\n\n2458/2458 [==============================] - 412s 168ms/step - loss: 2.3133 - haversine_loss: 2.3133\n\nEpoch 5/100\n\n2458/2458 [==============================] - 412s 168ms/step - loss: 2.2219 - haversine_loss: 2.2219\n\nEpoch 6/100\n\n2458/2458 [==============================] - 413s 168ms/step - loss: 2.1291 - haversine_loss: 2.1291\n\nEpoch 7/100\n\n2458/2458 [==============================] - 413s 168ms/step - loss: 2.0739 - haversine_loss: 2.0739\n\nEpoch 8/100\n\n2458/2458 [==============================] - 412s 168ms/step - loss: 2.0189 - haversine_loss: 2.0189\n\nEpoch 9/100\n\n2458/2458 [==============================] - 411s 167ms/step - loss: 1.9729 - haversine_loss: 1.9729\n\nEpoch 10/100\n\n2458/2458 [==============================] - 411s 167ms/step - loss: 1.9408 - haversine_loss: 1.9408\n\nEpoch 11/100\n\n2458/2458 [==============================] - 411s 167ms/step - loss: 1.9137 - haversine_loss: 1.9137\n\nEpoch 12/100\n\n2458/2458 [==============================] - 411s 167ms/step - loss: 1.8811 - haversine_loss: 1.8811\n\nEpoch 13/100\n\n2458/2458 [==============================] - 413s 168ms/step - loss: 1.8606 - haversine_loss: 1.8606\n\nEpoch 14/100\n\n2458/2458 [==============================] - 412s 168ms/step - loss: 1.8410 - haversine_loss: 1.8410\n\nEpoch 15/100\n\n2458/2458 [==============================] - 410s 167ms/step - loss: 1.8391 - haversine_loss: 1.8391\n\nEpoch 16/100\n\n2458/2458 [==============================] - 411s 167ms/step - loss: 1.8204 - haversine_loss: 1.8204\n\nEpoch 17/100\n\n2458/2458 [==============================] - 411s 167ms/step - loss: 1.7985 - haversine_loss: 1.7985\n\nEpoch 18/100\n\n2458/2458 [==============================] - 412s 168ms/step - loss: 1.7840 - haversine_loss: 1.7840\n\nEpoch 19/100\n\n2458/2458 [==============================] - 412s 168ms/step - loss: 1.7767 - haversine_loss: 1.7767\n\nEpoch 20/100\n\n2458/2458 [==============================] - 412s 168ms/step - loss: 1.7667 - haversine_loss: 1.7667\n\nEpoch 21/100\n\n2458/2458 [==============================] - 413s 168ms/step - loss: 1.7601 - haversine_loss: 1.7601\n\nEpoch 22/100\n\n2458/2458 [==============================] - 419s 170ms/step - loss: 1.7499 - haversine_loss: 1.7499\n\nEpoch 23/100\n\n2458/2458 [==============================] - 412s 168ms/step - loss: 1.7482 - haversine_loss: 1.7482\n\nEpoch 24/100\n\n2458/2458 [==============================] - 418s 170ms/step - loss: 1.7332 - haversine_loss: 1.7332\n\nEpoch 25/100\n\n2458/2458 [==============================] - 412s 168ms/step - loss: 1.7213 - haversine_loss: 1.7213\n\nEpoch 26/100\n\n2458/2458 [==============================] - 414s 168ms/step - loss: 1.7178 - haversine_loss: 1.7178\n\nEpoch 27/100\n\n2458/2458 [==============================] - 413s 168ms/step - loss: 1.7105 - haversine_loss: 1.7105\n\nEpoch 28/100\n\n2458/2458 [==============================] - 410s 167ms/step - loss: 1.6993 - haversine_loss: 1.6993\n\nEpoch 29/100\n\n2458/2458 [==============================] - 412s 167ms/step - loss: 1.7023 - haversine_loss: 1.7023\n\nEpoch 30/100\n\n2458/2458 [==============================] - 410s 167ms/step - loss: 1.7199 - haversine_loss: 1.7199\n\nEpoch 31/100\n\n2458/2458 [==============================] - 415s 169ms/step - loss: 1.6971 - haversine_loss: 1.6971\n\nEpoch 32/100\n\n2458/2458 [==============================] - 412s 168ms/step - loss: 1.6897 - haversine_loss: 1.6897\n\nEpoch 33/100\n\n2458/2458 [==============================] - 413s 168ms/step - loss: 1.6782 - haversine_loss: 1.6782\n\nEpoch 34/100\n\n2458/2458 [==============================] - 417s 170ms/step - loss: 1.6723 - haversine_loss: 1.6723\n\nEpoch 35/100\n\n2458/2458 [==============================] - 415s 169ms/step - loss: 1.6869 - haversine_loss: 1.6869\n\nEpoch 36/100\n\n2458/2458 [==============================] - 415s 169ms/step - loss: 1.6680 - haversine_loss: 1.6680\n\nEpoch 37/100\n\n2458/2458 [==============================] - 412s 167ms/step - loss: 1.6642 - haversine_loss: 1.6642\n\nEpoch 38/100\n\n2458/2458 [==============================] - 412s 168ms/step - loss: 1.6652 - haversine_loss: 1.6652\n\nEpoch 39/100\n\n2458/2458 [==============================] - 411s 167ms/step - loss: 1.6512 - haversine_loss: 1.6512\n\nEpoch 40/100\n\n2458/2458 [==============================] - 416s 169ms/step - loss: 1.6563 - haversine_loss: 1.6563\n\nEpoch 41/100\n\n2458/2458 [==============================] - 439s 179ms/step - loss: 1.6514 - haversine_loss: 1.6514\n\nEpoch 42/100\n\n2458/2458 [==============================] - 454s 185ms/step - loss: 1.6480 - haversine_loss: 1.6480\n\nEpoch 43/100\n\n2458/2458 [==============================] - 430s 175ms/step - loss: 1.6509 - haversine_loss: 1.6509\n\nEpoch 44/100\n\n2458/2458 [==============================] - 427s 174ms/step - loss: 1.6525 - haversine_loss: 1.6525\n\nEpoch 45/100\n\n2458/2458 [==============================] - 423s 172ms/step - loss: 1.6414 - haversine_loss: 1.6414\n\nEpoch 46/100\n\n2458/2458 [==============================] - 424s 172ms/step - loss: 1.6409 - haversine_loss: 1.6409\n\nEpoch 47/100\n\n2458/2458 [==============================] - 424s 172ms/step - loss: 1.6421 - haversine_loss: 1.6421\n\nEpoch 48/100\n\n2458/2458 [==============================] - 427s 174ms/step - loss: 1.6465 - haversine_loss: 1.6465\n\nEpoch 49/100\n\n2458/2458 [==============================] - 427s 174ms/step - loss: 1.6311 - haversine_loss: 1.6311\n\nEpoch 50/100\n\n2458/2458 [==============================] - 427s 174ms/step - loss: 1.6266 - haversine_loss: 1.6266\n\nEpoch 51/100\n\n2458/2458 [==============================] - 422s 172ms/step - loss: 1.6355 - haversine_loss: 1.6355\n\nEpoch 52/100\n\n2458/2458 [==============================] - 423s 172ms/step - loss: 1.6307 - haversine_loss: 1.6307\n\nEpoch 53/100\n\n2458/2458 [==============================] - 422s 172ms/step - loss: 1.6281 - haversine_loss: 1.6281\n\nEpoch 54/100\n\n2458/2458 [==============================] - 427s 174ms/step - loss: 1.6390 - haversine_loss: 1.6390\n\nEpoch 55/100\n\n2458/2458 [==============================] - 424s 173ms/step - loss: 1.6291 - haversine_loss: 1.6291\n\nEpoch 56/100\n\n2458/2458 [==============================] - 422s 172ms/step - loss: 1.6201 - haversine_loss: 1.6201\n\nEpoch 57/100\n\n2458/2458 [==============================] - 426s 173ms/step - loss: 1.6184 - haversine_loss: 1.6184\n\nEpoch 58/100\n\n2458/2458 [==============================] - 423s 172ms/step - loss: 1.6075 - haversine_loss: 1.6075\n\nEpoch 59/100\n\n2458/2458 [==============================] - 424s 172ms/step - loss: 1.6182 - haversine_loss: 1.6182\n\nEpoch 60/100\n\n2458/2458 [==============================] - 423s 172ms/step - loss: 1.6044 - haversine_loss: 1.6044\n\nEpoch 61/100\n\n2458/2458 [==============================] - 423s 172ms/step - loss: 1.6172 - haversine_loss: 1.6172\n\nEpoch 62/100\n\n2458/2458 [==============================] - 422s 172ms/step - loss: 1.6379 - haversine_loss: 1.6379\n\nEpoch 63/100\n\n2458/2458 [==============================] - 424s 172ms/step - loss: 1.6120 - haversine_loss: 1.6120\n\nEpoch 64/100\n\n2458/2458 [==============================] - 423s 172ms/step - loss: 1.6003 - haversine_loss: 1.6003\n\nEpoch 65/100\n\n2458/2458 [==============================] - 422s 172ms/step - loss: 1.5985 - haversine_loss: 1.5985\n\nEpoch 66/100\n\n2458/2458 [==============================] - 422s 172ms/step - loss: 1.6068 - haversine_loss: 1.6068\n\nEpoch 67/100\n\n2458/2458 [==============================] - 423s 172ms/step - loss: 1.5976 - haversine_loss: 1.5976\n\nEpoch 68/100\n\n2458/2458 [==============================] - 422s 172ms/step - loss: 1.5996 - haversine_loss: 1.5996\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "plt.plot(history_mc.history['haversine_loss'])\nplt.title('Training Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Haversine Loss in NM')",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1675656858968,
     "user": {
      "displayName": "Alex Spradling",
      "userId": "03803427225004929883"
     },
     "user_tz": 300
    },
    "id": "CV6l8WOL6cnd",
    "outputId": "111780a6-ea6a-4781-c6ec-9d67158e23fe"
   },
   "execution_count": 16,
   "outputs": [
    {
     "execution_count": 16,
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Haversine Loss in NM')"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "mc_model.save('mc_model.h5')",
   "metadata": {
    "executionInfo": {
     "elapsed": 4119,
     "status": "ok",
     "timestamp": 1675656921674,
     "user": {
      "displayName": "Alex Spradling",
      "userId": "03803427225004929883"
     },
     "user_tz": 300
    },
    "id": "zxc3AXFi7vbx"
   },
   "execution_count": 17,
   "outputs": []
  }
 ]
}